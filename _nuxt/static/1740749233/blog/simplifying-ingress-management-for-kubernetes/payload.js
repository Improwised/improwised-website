__NUXT_JSONP__("/blog/simplifying-ingress-management-for-kubernetes", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C){return {data:[{blog:{id:o,status:p,sort:17,date_created:"2025-01-10T05:54:53.222Z",date_updated:"2025-01-10T12:12:02.448Z",title:v,description:"\u003Cp dir=\"ltr\"\u003EManaging ingress traffic in a Kubernetes cluster is a critical aspect of ensuring the accessibility and security of your applications. This guide will walk you through the process of deploying a Traefik cluster on Kuberntes, including the setup of automatic TLS using Let's Encrypt.\u003C\u002Fp\u003E",seo_title:v,seo_description:"Managing ingress traffic in a Kubernetes cluster is a critical aspect of ensuring the accessibility and security of your applications. This guide will walk you through the process of deploying a Traefik cluster on Kuberntes, including the setup of automatic TLS using Let's Encrypt.",content:"\u003Ch3 dir=\"ltr\"\u003EPrerequisites\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EBefore proceeding, ensure you have the following:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EEnsure you have a Kubernetes cluster set up.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EInstall Helm for package management.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EHave a domain name that resolves to the public IP of your Kubernetes cluster.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp dir=\"ltr\"\u003E\u003Cimg src=\"\u002F_nuxt\u002Fimage\u002F0dce84.png\" alt=\"Traefik (2)\"\u003E\u003C\u002Fp\u003E\n\u003Ch2 dir=\"ltr\"\u003ESetting Up the Kubernetes Cluster\u003C\u002Fh2\u003E\n\u003Cp dir=\"ltr\"\u003EIf you don't already have a Kubernetes cluster, you can set one up using your preferred method (e.g., using Minikube, kind, or any other Kubernetes distribution).\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003EInstalling Helm\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003ETo manage packages in your Kubernetes cluster, you need Helm. Hereâ€™s how to install it:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003Ecurl -fsSL -o get_helm.sh https:\u002F\u002Fraw.githubusercontent.com\u002Fhelm\u002Fhelm\u002Fmaster\u002Fscripts\u002Fget-helm-3\nchmod 700 get_helm.sh\n.\u002Fget_helm.sh\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003EInstalling Traefik via Helm\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003ETo install Traefik using Helm, you need to configure the traefik-values.yaml file. Here is an example configuration that includes Let's Encrypt for automatic TLS:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003E# traefik-values.yaml\n\nlogs:\n  general:\n    level: DEBUG\n\nservice:\n  type: LoadBalancer\n\npersistence:\n  enabled: true\n\ncertificatesResolvers:\n  letsencrypt:\n    acme:\n      email: \"your@email.com\" \n      storage: \"traefik-acme.json\"\n      keyType: \"RSA4096\"\n      tlsChallenge: {}\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp dir=\"ltr\"\u003EYou can override the\u003Ca href=\"http:\u002F\u002Facme.email\"\u003E acme.email\u003C\u002Fa\u003E field directly in the helm install command if needed:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003Ehelm repo add traefik https:\u002F\u002Fhelm.traefik.io\u002Ftraefik\nhelm repo update\nhelm install traefik traefik\u002Ftraefik --set acme.email=your@email.com\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003EConfiguring DNS for Traefik\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EAfter installing Traefik, you need to set up a DNS name for the public IP of the Traefik controller.\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003E# Get the public IP of the Traefik service\nPUBLIC_IP=$(kubectl get svc traefik -n kube-system -o jsonpath='{.status.loadBalancer.ingress.hostname}')\n\n# Update the DNS name for the public IP\nDNSNAME=$(az network public-ip show --ids $(kubectl get svc traefik -n kube-system -o jsonpath='{.status.loadBalancer.ingress.hostname}' | cut -d '.' -f 1) --query dnsSettings.fqdn -o tsv)\necho \"DNSNAME: $DNSNAME\"\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003EDeploying a Sample Application\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003ETo demonstrate the functionality of Traefik, you can deploy a sample application. Here is an example of how to deploy the azure-vote-app:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003E# azure-vote-app.yaml\n\napiVersion: apps\u002Fv1\nkind: Deployment\nmetadata:\n  name: azure-vote-back\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: azure-vote-back\n  template:\n    metadata:\n      labels:\n        app: azure-vote-back\n    spec:\n      containers:\n      - name: azure-vote-back\n        image: mcr.microsoft.com\u002Foss\u002Fnginx\u002Fnginx:1.15.5-alpine\n        ports:\n        - containerPort: 80\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: azure-vote-back\nspec:\n  selector:\n    app: azure-vote-back\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n  type: ClusterIP\n\n---\napiVersion: apps\u002Fv1\nkind: Deployment\nmetadata:\n  name: azure-vote-front\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: azure-vote-front\n  template:\n    metadata:\n      labels:\n        app: azure-vote-front\n    spec:\n      containers:\n      - name: azure-vote-front\n        image: mcr.microsoft.com\u002Foss\u002Fnginx\u002Fnginx:1.15.5-alpine\n        ports:\n        - containerPort: 80\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: azure-vote-front\nspec:\n  selector:\n    app: azure-vote-front\n  ports:\n  - name: http\n    port: 80\n    targetPort: 80\n  type: ClusterIP\n\n---\napiVersion: networking.k8s.io\u002Fv1\nkind: Ingress\nmetadata:\n  name: azure-vote-ingress\n  annotations:\n    traefik.ingress.kubernetes.io\u002Frouter.tls.certresolver: letsencrypt\n    traefik.ingress.kubernetes.io\u002Frouter.entrypoints: websecure\nspec:\n  rules:\n  - host: ${DNSNAME}\n    http:\n      paths:\n      - path: \u002F\n        pathType: Exact\n        backend:\n          service:\n            name: azure-vote-front\n            port:\n              number: 80\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp dir=\"ltr\"\u003EUpdate the host field in the Ingress resource to match your Traefik public IP FQDN:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003Esed -i \"s\u002Fhost: &lt;DNSNAME&gt;.&lt;LOCATION&gt;.cloudapp.azure.com\u002Fhost: ${DNSNAME}\u002Fg\" azure-vote-app.yaml\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp dir=\"ltr\"\u003EThen, apply the configuration:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003Ekubectl create ns azure-vote\nkubectl apply -f azure-vote-app.yaml -n azure-vote\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003EUsing IngressRoute CRD\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003ETraefik also supports the IngressRoute CRD for more advanced routing configurations. Here is an example of how to use it:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003E# azure-vote-ingressroute.yaml\n\napiVersion: traefik.io\u002Fv1alpha1\nkind: IngressRoute\nmetadata:\n  name: azure-vote-ingressroute\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`${DNSNAME}`)\n      kind: Rule\n      services:\n        - name: azure-vote-front\n          port: 80\n  tls:\n    certResolver: letsencrypt\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp dir=\"ltr\"\u003EApply the IngressRoute configuration:\u003C\u002Fp\u003E\n\u003Cdiv dir=\"ltr\" align=\"left\"\u003E\n\u003Cpre\u003E\u003Ccode\u003Ekubectl apply -f azure-vote-ingressroute.yaml -n azure-vote\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003EMiddleware Configuration\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EYou can also configure middleware using Traefik's CRDs. Here is an example of how to set up a middleware to add security headers:\u003C\u002Fp\u003E\n\u003Cdiv dir=\"ltr\" align=\"left\"\u003E\n\u003Cpre\u003E\u003Ccode\u003E# azure-vote-middleware.yaml\n\napiVersion: traefik.io\u002Fv1alpha1\nkind: Middleware\nmetadata:\n  name: test-header\nspec:\n  headers:\n    frameDeny: true\n    browserXssFilter: true\nApply the middleware configuration:\nkubectl apply -f azure-vote-middleware.yaml -n azure-vote\nThen, reference the middleware in your IngressRoute:\n# Updated azure-vote-ingressroute.yaml\n\napiVersion: traefik.io\u002Fv1alpha1\nkind: IngressRoute\nmetadata:\n  name: azure-vote-ingressroute\nspec:\n  entryPoints:\n    - websecure\n  routes:\n    - match: Host(`${DNSNAME}`)\n      kind: Rule\n      middlewares:\n        - name: test-header\n      services:\n        - name: azure-vote-front\n          port: 80\n  tls:\n    certResolver: letsencrypt\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp\u003E\u003Cstrong\u003E&nbsp;\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EWhen considering high availability in a setup involving multiple instances of Traefik with Let's Encrypt, it is important to note that Let's Encrypt itself does not inherently provide high availability solutions. However, Let's Encrypt does offer robust security features for obtaining and managing TLS certificates.\u003C\u002Fp\u003E\n\u003Ch2 dir=\"ltr\"\u003ELimitations with Traefik and Let's Encrypt\u003C\u002Fh2\u003E\n\u003Cp dir=\"ltr\"\u003EUsing multiple instances of Traefik with Let's Encrypt can be challenging due to the nature of the ACME challenge. Each Traefik instance may attempt to renew the certificate independently, leading to conflicts and overwriting of certificates.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EHere are some recommended approaches to address this issue:\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E1. Centralized Storage with Shared File System\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EUse a shared file system (e.g., NFS, Ceph, or AWS EFS) that is accessible to all Traefik instances.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EConfigure Traefik to use the shared file system as the storage backend for ACME certificates by specifying the acme.json file location.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EExample configuration in traefik.yml:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003EcertificatesResolvers:\n  letsEncrypt:\n    acme:\n      email: \"your-email@example.com\"\n      storage: \"\u002Fshared\u002Facme.json\"\n      httpChallenge:\n        entryPoint: \"web\"\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp\u003E\u003Cstrong\u003E&nbsp;\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E2. Use a Distributed Key-Value Store\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003ETraefik supports using distributed key-value stores like Consul, Etcd, or Redis to store ACME certificates.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EThis ensures that all instances have consistent access to certificate data and can avoid conflicts.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EExample configuration for Consul:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003EcertificatesResolvers:\n  letsEncrypt:\n    acme:\n      email: \"your-email@example.com\"\n      storage: \"traefik\u002Facme\u002Faccount\"\n      httpChallenge:\n        entryPoint: \"web\"\nproviders:\n  consul:\n    endpoints:\n      - \"127.0.0.1:8500\"\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003E3. Avoid Simultaneous Renewal Attempts\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EUse a leader-election mechanism (e.g., Kubernetes leader-election or a similar process in other environments) to designate a single Traefik instance as the one responsible for certificate renewal.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003ENon-leader instances can still use the certificates but do not attempt renewal.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E4. DNS Challenge for Cert Management\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EConsider using the DNS challenge for certificate validation, especially in a multi-instance setup. This approach is stateless and avoids potential conflicts during HTTP challenges.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EExample DNS challenge configuration:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003EcertificatesResolvers:\n  letsEncrypt:\n    acme:\n      email: \"your-email@example.com\"\n      storage: \"\u002Fshared\u002Facme.json\"\n      dnsChallenge:\n        provider: \"cloudflare\"\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp dir=\"ltr\"\u003EBy implementing one or more of these strategies, you can ensure smooth certificate management across multiple Traefik instances and avoid the challenges associated with Let's Encrypt's ACME protocol.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003EConclusion\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EDeploying Traefik as an ingress controller on Kubernetes with automatic TLS using Let's Encrypt or Cert-Manager simplifies the management of ingress traffic and improves the security of your applications. By following the steps outlined in this guide, you can set up a robust and scalable ingress solution that meets the demands of your Kubernetes workloads.\u003C\u002Fp\u003E\n\u003C\u002Fdiv\u003E\n\u003C\u002Fdiv\u003E",slug:"simplifying-ingress-management-for-kubernetes",user_created:{id:b,first_name:c,last_name:d,email:e,password:f,location:a,title:g,description:a,tags:a,avatar:h,language:a,tfa_secret:a,status:i,role:j,token:a,last_access:k,last_page:l,provider:m,external_identifier:a,auth_data:a,email_notifications:n,appearance:a,theme_dark:a,theme_light:a,theme_light_overrides:a,theme_dark_overrides:a},user_updated:{id:b,first_name:c,last_name:d,email:e,password:f,location:a,title:g,description:a,tags:a,avatar:h,language:a,tfa_secret:a,status:i,role:j,token:a,last_access:k,last_page:l,provider:m,external_identifier:a,auth_data:a,email_notifications:n,appearance:a,theme_dark:a,theme_light:a,theme_light_overrides:a,theme_dark_overrides:a},image:{id:"848b119e-0969-4831-b652-2b90987580a6",storage:q,filename_disk:"848b119e-0969-4831-b652-2b90987580a6.png",filename_download:"tls traefik-min.png",title:"TLS Traefik Min",type:r,folder:s,uploaded_by:b,created_on:"2025-01-10T12:03:08.143Z",modified_by:a,modified_on:"2025-01-10T12:03:10.127Z",charset:a,filesize:"992278",width:w,height:w,duration:a,embed:a,description:a,location:a,tags:a,metadata:{},focal_point_x:a,focal_point_y:a,tus_id:a,tus_data:a,uploaded_on:"2025-01-10T12:03:10.120Z"},tags:[{id:35,blog_id:o,tags_id:{name:"Traefik"}},{id:36,blog_id:o,tags_id:{name:"Kubernetes"}}]},blogList:[{id:x,status:p,sort:a,date_created:"2025-02-25T12:12:15.443Z",date_updated:"2025-02-26T05:20:18.465Z",title:y,description:"\u003Cp\u003EWhen it comes to deploying and managing applications, especially in cloud-native and microservices-based environments, several deployment models and strategies are available. The Open Application Model (OAM) is one such model that has gained significant attention due to its platform-agnostic and declarative approach to application deployment.\u003C\u002Fp\u003E",seo_title:y,seo_description:"Explore how the Open Application Model (OAM) simplifies cloud-native development with role separation and modular design, contrasting Kubernetes-native tools, PaaS, and serverless models for flexibility and scalability",content:"\u003Cp\u003EThis blog will delve into the technical aspects of OAM and compare it with other prominent application deployment strategies, highlighting their differences, advantages, and potential consequences.\u003C\u002Fp\u003E\n\u003Ch2 dir=\"ltr\"\u003EOpen Application Model (OAM)\u003C\u002Fh2\u003E\n\u003Cp dir=\"ltr\"\u003E\u003Cimg src=\"https:\u002F\u002Fdata.improwised.com\u002Fassets\u002Ff512dcfe-60e0-4886-bb0d-1a14fa2bfa88.png?width=2240&amp;height=1260\" alt=\"Open Application Model\"\u003E\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EOAM is a specification designed to create cloud-native, platform-independent applications. It uses a declarative approach to define application components, which simplifies the process of specifying how an application should be deployed and managed. OAM separates the application logic from the underlying infrastructure, allowing developers to focus on creating and deploying applications without worrying about the specifics of the supporting platform.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EKey Components\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EComponents: These correspond to workloads or resources within the application.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ETraits: These define additional capabilities or configurations for the components, such as scaling or monitoring.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EPolicies: These specify the rules and constraints for the application deployment.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EDeployment Workflows: These outline the steps involved in deploying the application.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp dir=\"ltr\"\u003EOAM allows developers to define multiple workloads in a single specification, although best practices suggest limiting the number of components within an application to maintain manageability.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EPlatform Neutrality\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EOne of the significant advantages of OAM is its platform neutrality. Applications defined using OAM can be deployed across various cloud-native platforms without requiring modifications. This is particularly useful in multi-cloud environments, where the ability to deploy applications consistently across different platforms can reduce deployment and management complexities.\u003C\u002Fp\u003E\n\u003Ch2 dir=\"ltr\"\u003E\u003Cbr\u003EBlue\u002FGreen Deployment\u003C\u002Fh2\u003E\n\u003Cp dir=\"ltr\"\u003EThe Blue\u002FGreen deployment strategy involves running two versions of the application simultaneously: the current version (blue) and the new version (green). This approach allows for testing the new version in a live environment while keeping the old version available for immediate rollback if necessary.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EKey Aspects\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ETraffic Management: Load balancers are used to redirect traffic between the blue and green environments.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EDatabase Compatibility: Both environments must use compatible data formats and schema to ensure seamless data sharing.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ERollback Capability: The ability to quickly switch back to the previous version if issues arise with the new version.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EComparison with OAM\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EUnlike OAM, which focuses on defining and deploying application components in a declarative manner, Blue\u002FGreen deployment is more about managing the transition between different versions of an application. While OAM does not inherently support versioning and rollback mechanisms, it can be integrated with service meshes like Open Service Mesh (OSM) to achieve similar traffic management and rollback capabilities.\u003C\u002Fp\u003E\n\u003Ch2 dir=\"ltr\"\u003E\u003Cbr\u003EContinuous Deployment (CD)\u003C\u002Fh2\u003E\n\u003Cp dir=\"ltr\"\u003EContinuous Deployment is a strategy where new versions of the application are released to production automatically after passing through automated testing and validation. This approach eliminates the need for manual testing or approval processes, allowing for rapid deployment of new features\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EKey Aspects\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EAutomated Testing: New code changes are deployed to production only after passing automated tests.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ENo Manual Gates: Unlike Continuous Delivery, CD does not include manual approval steps before deployment to production.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EComparison with OAM\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EOAM and Continuous Deployment share the goal of streamlining the deployment process, but they approach it differently. OAM focuses on the declarative definition of application components and their deployment workflows, whereas Continuous Deployment is about automating the release process. OAM can be used in conjunction with CD pipelines to ensure that the application components are defined and deployed consistently across different environments.\u003C\u002Fp\u003E\n\u003Ch2 dir=\"ltr\"\u003E\u003Cbr\u003ERecreate Deployment\u003C\u002Fh2\u003E\n\u003Cp dir=\"ltr\"\u003EIn the Recreate deployment strategy, the old version of the application is completely shut down before the new version is deployed. This results in downtime for the application until the new version is fully deployed and operational.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EKey Aspects\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EDowntime: The application is unavailable during the transition from the old to the new version.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ECost-Effectiveness: This strategy is cheaper as it does not require load balancers or complex traffic management.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EComparison with OAM\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EOAM does not inherently support recreate deployment strategies, as it is designed to manage and deploy application components without downtime. However, if an application defined using OAM needs to undergo a complete overhaul, the recreate strategy could be manually implemented, though it would not align with OAM's principles of platform neutrality and minimal downtime.\u003C\u002Fp\u003E\n\u003Ch2 dir=\"ltr\"\u003E\u003Cbr\u003EShadow Deployment\u003C\u002Fh2\u003E\n\u003Cp dir=\"ltr\"\u003EShadow deployment involves running both the old and new versions of the application simultaneously, but the new version receives traffic indirectly through the old version. This approach helps in testing the new version in a live environment without directly impacting users.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EKey Aspects\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EIndirect Traffic: The new version receives traffic from the old version, reducing the risk of direct user impact.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EResponse Time: The response time may be prolonged due to the indirect traffic routing.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EComparison with OAM\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003ESimilar to Blue\u002FGreen deployment, Shadow deployment is more about managing the transition and testing of new application versions. OAM, with its focus on declarative application definitions, does not natively support shadow deployment. However, integrating OAM with service meshes could facilitate similar traffic management and testing scenarios.\u003C\u002Fp\u003E\n\u003Ch2 dir=\"ltr\"\u003E\u003Cbr\u003EConclusion&nbsp;\u003C\u002Fh2\u003E\n\u003Cp\u003EOAM, while offering significant flexibility and platform neutrality, presents several technical considerations. Its declarative nature, while powerful, can introduce complexity, particularly for smaller teams or those new to this deployment model. Grasping OAM's components, traits, and policies requires a deeper understanding. Integrating OAM with other deployment strategies, such as Blue\u002FGreen or Continuous Deployment, can enhance its capabilities but also adds layers of complexity that must be effectively managed. Furthermore, while OAM's ability to define multiple workloads within a single specification can improve scalability, it necessitates careful management to prevent system overload.\u003C\u002Fp\u003E\n\u003Cp\u003EOperationalizing OAM can have significant consequences. Strategies like Recreate deployments, if not carefully managed, can lead to significant downtime, negatively impacting user experience and disrupting business operations. Techniques like Blue\u002FGreen and Shadow deployments require running multiple application versions concurrently, which can increase resource consumption, including storage, computing power, and hardware costs. Continuous Deployment, while enabling rapid deployments, heavily relies on robust automated testing and validation. Any deficiencies in these processes can result in deploying faulty code to production, potentially causing service disruptions.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003ESelecting the appropriate deployment strategy is critical. For instance, OAM is well-suited for intricate, cloud-native applications, whereas Blue\u002FGreen deployments might be more suitable for applications requiring frequent version updates. Irrespective of the chosen strategy, meticulous monitoring and testing are paramount to guarantee the application functions as intended in production. Continuously reviewing and refining deployment processes is essential to accommodate evolving requirements and mitigate potential risks.\u003C\u002Fp\u003E",slug:"comparing-open-application-model",user_created:{id:b,first_name:c,last_name:d,email:e,password:f,location:a,title:g,description:a,tags:a,avatar:h,language:a,tfa_secret:a,status:i,role:j,token:a,last_access:k,last_page:l,provider:m,external_identifier:a,auth_data:a,email_notifications:n,appearance:a,theme_dark:a,theme_light:a,theme_light_overrides:a,theme_dark_overrides:a},user_updated:{id:b,first_name:c,last_name:d,email:e,password:f,location:a,title:g,description:a,tags:a,avatar:h,language:a,tfa_secret:a,status:i,role:j,token:a,last_access:k,last_page:l,provider:m,external_identifier:a,auth_data:a,email_notifications:n,appearance:a,theme_dark:a,theme_light:a,theme_light_overrides:a,theme_dark_overrides:a},image:{id:"d346114d-cfda-41bc-87a7-6dcf95ce1e24",storage:q,filename_disk:"d346114d-cfda-41bc-87a7-6dcf95ce1e24.png",filename_download:"56376913.png",title:"56376913",type:r,folder:s,uploaded_by:b,created_on:"2025-02-25T12:02:01.536Z",modified_by:a,modified_on:"2025-02-25T12:02:01.757Z",charset:a,filesize:"4582",width:z,height:z,duration:a,embed:a,description:a,location:a,tags:a,metadata:{},focal_point_x:a,focal_point_y:a,tus_id:a,tus_data:a,uploaded_on:"2025-02-25T12:02:01.754Z"},tags:[{id:51,blog_id:x,tags_id:o}]},{id:t,status:p,sort:a,date_created:"2025-02-21T08:26:59.290Z",date_updated:"2025-02-21T11:28:19.246Z",title:A,description:"\u003Cp\u003EKubernetes has become the de facto standard for container orchestration in modern cloud-native ecosystems. Yet, as platform engineering evolves, it's essential to recognize that Kubernetes is not the end goal but rather a foundational layer for more advanced, scalable, and developer-friendly platforms. Kubernetes provides a unified infrastructure abstraction that simplifies complex systems.\u003C\u002Fp\u003E",seo_title:A,seo_description:"Kubernetes has become the de facto standard for container orchestration in modern cloud-native ecosystems. ",content:"\u003Cp dir=\"ltr\"\u003EHowever, the true destination is the seamless experience of a platform product that supports continuous innovation.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EIn this blog, we&rsquo;ll explore the evolution of Kubernetes, its pivotal role as a foundational layer, and why platform engineering moves beyond Kubernetes to focus on developer experience, automation, and operational excellence.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003E1. Kubernetes as the Backbone: A Historical Perspective\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EKubernetes, born from Google&rsquo;s Borg system, emerged as an open-source solution for container orchestration in 2014. Its rapid adoption was fueled by the rise of microservices architectures and the need for scalable, resilient infrastructure across diverse environments. Kubernetes simplified tasks like container deployment, scaling, and networking, enabling organizations to manage applications consistently across on-prem, hybrid, and public clouds.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EHowever, while Kubernetes became synonymous with cloud-native applications, it also introduced new layers of complexity. Developers now had to navigate YAML configurations, Helm charts, and intricate networking setups. Platform engineers stepped in to bridge this gap by abstracting Kubernetes's complexity through Internal Developer Platforms (IDPs).\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003E2. Kubernetes as a Foundation: The Role of Infrastructure Abstraction\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EIn platform engineering, Kubernetes is best viewed as an infrastructure abstraction layer rather than a complete solution. It provides the necessary primitives to build higher-level capabilities like self-service provisioning, infrastructure orchestration, and environment management. Kubernetes acts as the control plane for platform operations, offering:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EInfrastructure Integration: Managing compute, storage, and networking resources across clouds.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EScalability and Reliability: Autoscaling capabilities that adapt to application demands.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ENetwork Abstractions: Simplifying inter-service communication through service meshes and ingress controllers.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp dir=\"ltr\"\u003EThis abstraction is crucial for reducing the cognitive load on developers, enabling them to focus on application logic rather than infrastructure nuances.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003E3. Why Kubernetes Is Not the Destination\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EWhile Kubernetes solves many infrastructure challenges, it is not inherently designed to address all aspects of the software delivery lifecycle. Here are&nbsp; several reasons why Kubernetes should be seen as a stepping stone:\u003C\u002Fp\u003E\n\u003Ch4 dir=\"ltr\"\u003Ea) Complexity Overload\u003C\u002Fh4\u003E\n\u003Cp dir=\"ltr\"\u003EKubernetes configurations can quickly become unmanageable for application developers, especially when dealing with CRDs (Custom Resource Definitions), operators, and network policies.\u003C\u002Fp\u003E\n\u003Ch4 dir=\"ltr\"\u003Eb) Lack of Developer Experience Features\u003C\u002Fh4\u003E\n\u003Cp dir=\"ltr\"\u003EKubernetes focuses on infrastructure management rather than providing a user-friendly interface for developers. It lacks out-of-the-box support for workflows like CI\u002FCD, service discovery, and resource tracking.\u003C\u002Fp\u003E\n\u003Ch4 dir=\"ltr\"\u003Ec) Operational Overhead\u003C\u002Fh4\u003E\n\u003Cp dir=\"ltr\"\u003EMaintaining Kubernetes clusters requires specialized knowledge in monitoring, security, and cost management. Without a platform layer, teams often spend excessive time on infrastructure operations instead of delivering features.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003E4. Moving Beyond Kubernetes: The Platform Engineering Perspective\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EThe goal of modern platform engineering is to build a product-like experience on top of Kubernetes. This approach transforms infrastructure into a self-service, developer-friendly environment that abstracts away operational complexities. Key strategies include:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EInternal Developer Platforms (IDPs): Tools like Backstage provide intuitive interfaces for developers to manage services, track deployments, and access documentation.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EGitOps Automation: Adopting GitOps practices with tools like Flux and ArgoCD ensures infrastructure consistency and simplifies operations.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EObservability and Security Layers: Integrating OpenTelemetry and Prometheus for real-time monitoring and policy enforcement.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp dir=\"ltr\"\u003EBy treating the platform as a product, organizations shift from infrastructure management to innovation, enabling faster feature delivery and improved system reliability.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003E5. The Future: Kubernetes as a Utility, Not a Destination\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EAs the cloud-native landscape matures, Kubernetes is evolving into a utility&mdash;a ubiquitous layer of infrastructure similar to power grids. It suggests that future platforms will increasingly leverage:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EAI-Augmented Operations: Automating scaling, resource allocation, and anomaly detection.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EEdge Computing and Wasm: Expanding Kubernetes beyond centralized data centers to edge environments.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ESustainable Cloud Practices: Implementing FinOps strategies to optimize resource utilization and reduce environmental impact.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp dir=\"ltr\"\u003EIn this context, platform engineers will focus more on developer experience, security, and process optimization than on Kubernetes internals.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003EConclusion: Kubernetes as the Starting Point for Platform Innovation\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EKubernetes provides a powerful foundation for building modern platforms, but the real value lies in the layers built above it. Platform engineering transforms this infrastructure foundation into a streamlined, self-service experience that empowers developers, accelerates innovation, and reduces operational complexity. So, Kubernetes is the launchpad&mdash;not the landing zone&mdash;for the next era of cloud-native applications.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003ESo, while Kubernetes remains essential, the true destination is a developer-centric platform that makes cloud-native development simpler, faster, and more sustainable. The journey has just begun, and platform engineering is leading the way.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EReady to build a platform beyond Kubernetes? Discover how our platform engineering services can help you build scalable, secure, and developer-friendly environments.\u003C\u002Fp\u003E",slug:"kubernetes-why-its-foundation-not-destination",user_created:{id:b,first_name:c,last_name:d,email:e,password:f,location:a,title:g,description:a,tags:a,avatar:h,language:a,tfa_secret:a,status:i,role:j,token:a,last_access:k,last_page:l,provider:m,external_identifier:a,auth_data:a,email_notifications:n,appearance:a,theme_dark:a,theme_light:a,theme_light_overrides:a,theme_dark_overrides:a},user_updated:{id:b,first_name:c,last_name:d,email:e,password:f,location:a,title:g,description:a,tags:a,avatar:h,language:a,tfa_secret:a,status:i,role:j,token:a,last_access:k,last_page:l,provider:m,external_identifier:a,auth_data:a,email_notifications:n,appearance:a,theme_dark:a,theme_light:a,theme_light_overrides:a,theme_dark_overrides:a},image:{id:"d3d30b46-3a8e-49f0-8699-31f4654e1204",storage:q,filename_disk:"d3d30b46-3a8e-49f0-8699-31f4654e1204.png",filename_download:"images.png",title:"Images",type:r,folder:s,uploaded_by:b,created_on:"2025-02-21T11:28:14.098Z",modified_by:a,modified_on:"2025-02-21T11:28:14.568Z",charset:a,filesize:"5814",width:B,height:B,duration:a,embed:a,description:a,location:a,tags:a,metadata:{},focal_point_x:a,focal_point_y:a,tus_id:a,tus_data:a,uploaded_on:"2025-02-21T11:28:14.565Z"},tags:[{id:48,blog_id:t,tags_id:5},{id:49,blog_id:t,tags_id:13},{id:50,blog_id:t,tags_id:16}]},{id:u,status:p,sort:a,date_created:"2025-02-18T12:11:20.223Z",date_updated:"2025-02-18T12:50:34.786Z",title:C,description:"\u003Cp\u003EThis blog will delve into the technical details of implementing OAuth2 authorization using Keycloak as the identity and access management (IAM) solution, and Keycloak Gatekeeper as the authentication proxy. This setup is particularly useful for securing web applications deployed in a Kubernetes environment.\u003C\u002Fp\u003E",seo_title:C,seo_description:"This blog will delve into the technical details of implementing OAuth2 authorization using Keycloak as the identity and access management (IAM) solution, and Keycloak Gatekeeper as the authentication proxy. ",content:"\u003Ch3\u003EKeycloak Overview\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EKeycloak is an open-source IAM platform provided by Red Hat&rsquo;s JBoss. It supports various authentication and authorization protocols, including OpenID Connect (OIDC) and SAML 2.0. For most use cases, OIDC is recommended due to its modern and efficient implementation compared to SAML.\u003C\u002Fp\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003ESetting Up Keycloak\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003E\u003Cimg src=\"https:\u002F\u002Fdata.improwised.com\u002Fassets\u002F432ef2c1-8e8a-40aa-9c2e-9ac662960fd4.png?width=1472&amp;height=832\" alt=\"Client\"\u003E\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EBefore integrating Keycloak with Gatekeeper, you need to have a working Keycloak installation. Here are the key steps:\u003C\u002Fp\u003E\n\u003Col\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EInstall Keycloak:\u003Cbr\u003EDownload and install Keycloak from the official Red Hat website or use a Docker image.\u003Cbr\u003EStart the Keycloak server and access the administration console.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Col start=\"2\"\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ECreate a Realm:\u003Cbr\u003EIn the Keycloak administration console, create a new realm or use an existing one.\u003Cbr\u003EConfigure the realm settings as necessary.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Col start=\"3\"\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003ECreate a Client:\u003Cbr\u003EWithin the realm, create a new client application.\u003Cbr\u003ESet the Client ID and Access Type to confidential.\u003Cbr\u003EConfigure the Valid Redirect URLs to match your application's URL.\u003Cbr\u003ENote the Client Secret from the \"Credentials\" tab.\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Ch3 dir=\"ltr\"\u003E\u003Cbr\u003EConfiguring Keycloak Gatekeeper\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EKeycloak Gatekeeper is a transparent authentication proxy that integrates with the Keycloak authentication service. Here&rsquo;s how to set it up:\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003EAuthentication Modes\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EGatekeeper supports both access tokens in browser cookies and bearer tokens in the Authorization header. This flexibility allows it to handle traditional clients and modern browser-based clients.\u003C\u002Fp\u003E\n\u003Ch4 dir=\"ltr\"\u003EConfiguration Steps\u003C\u002Fh4\u003E\n\u003Col\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EDeploy Gatekeeper:\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Cp dir=\"ltr\"\u003EGatekeeper can be deployed as a sidecar container within the same Kubernetes pod as your application or as a standalone service.\u003Cbr\u003EEnsure the Kubernetes service points to the Gatekeeper rather than the application directly.\u003Cbr\u003E\u003Cbr\u003E\u003C\u002Fp\u003E\n\u003Col start=\"2\"\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EConfigure Gatekeeper Client in Keycloak:\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Cp dir=\"ltr\"\u003EIn the Keycloak administration console, create a new client for Gatekeeper.\u003Cbr\u003EEnsure the Gatekeeper client is configured with the proper \"audience\" token mapper. This is crucial as Gatekeeper expects to be listed in the audience claim of ID tokens brought back by Keycloak.\u003C\u002Fp\u003E\n\u003Col start=\"3\"\u003E\n\u003Cli dir=\"ltr\" aria-level=\"1\"\u003E\n\u003Cp dir=\"ltr\" role=\"presentation\"\u003EGatekeeper Configuration File:\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Cp dir=\"ltr\"\u003ECreate a configuration file for Gatekeeper. Here is an example:\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003Ediscovery-url: https:\u002F\u002Fyour-keycloak-instance.com\u002Fauth\u002Frealms\u002Fyour-realm\u002F.well-known\u002Fopenid-configuration\nclient-id: gatekeeper-client\nclient-secret: your-client-secret\nencryption-key: your-encryption-key\nredirect-url: https:\u002F\u002Fyour-application-url.com\nresources:\n  - uri: \u002Fprotected-path\n    methods:\n      - GET\n- POST\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp dir=\"ltr\"\u003ERun Gatekeeper: Start the Gatekeeper service using the configuration file.\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003Edocker run -d --name keycloak-gatekeeper \\\n  -v \u002Fpath\u002Fto\u002Fconfig.yaml:\u002Fconfig.yaml \\\n  oneconcern\u002Fkeycloak-gatekeeper:latest \\\n--config \u002Fconfig.yaml\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003EIntegrating with Kubernetes\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003ETo integrate Gatekeeper with your Kubernetes deployment, you can use Kubernetes services and ingress resources.\u003C\u002Fp\u003E\n\u003Ch4 dir=\"ltr\"\u003EUsing Ingress Annotations\u003C\u002Fh4\u003E\n\u003Cp dir=\"ltr\"\u003EYou can protect your web applications using ingress annotations. Here&rsquo;s an example of how to configure an Nginx ingress to use OAuth2 Proxy (which can be replaced or complemented with Gatekeeper):\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003ECreate an Ingress Resource:\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EDefine an ingress resource with annotations that point to the OAuth2 Proxy or Gatekeeper service.\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003EapiVersion: networking.k8s.io\u002Fv1\nkind: Ingress\nmetadata:\n  name: protected-ingress\n  annotations:\n    nginx.ingress.kubernetes.io\u002Fauth-type: \"oauth2\"\n    nginx.ingress.kubernetes.io\u002Fauth-secret: \"oauth2-proxy-client-secret\"\n    nginx.ingress.kubernetes.io\u002Fauth-realm: \"Protected Area\"\nspec:\n  rules:\n  - host: your-application-url.com\n    http:\n      paths:\n      - path: \u002Fprotected-path\n        pathType: Prefix\n        backend:\n          service:\n            name: your-service-name\n            Port:\n number: 80\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Cp dir=\"ltr\"\u003EDeploy OAuth2 Proxy or Gatekeeper:\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EDeploy the OAuth2 Proxy or Gatekeeper service using a Helm chart or a Kubernetes deployment.\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003Ehelm upgrade --install gatekeeper .\u002Fcharts\u002Fgatekeeper --values gatekeeper\u002Fvalues-gatekeeper.yml\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003EAccessing and Decoding JSON Web Tokens (JWTs)\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EOnce authenticated, the application can access and decode the Keycloak JSON Web Token (JWT) to implement fine-grained authorization.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EPassing the Authorization Header:\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EConfigure Gatekeeper or OAuth2 Proxy to pass the authorization header to the application.\u003C\u002Fp\u003E\n\u003Cdiv dir=\"ltr\" align=\"left\"\u003E\n\u003Ctable\u003E\u003Ccolgroup\u003E\u003C\u002Fcolgroup\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\n\u003Cpre\u003E\u003Ccode\u003Epass_authorization_header: true\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003C\u002Ftd\u003E\n\u003C\u002Ftr\u003E\n\u003C\u002Ftbody\u003E\n\u003C\u002Ftable\u003E\n\u003C\u002Fdiv\u003E\n\u003Cp dir=\"ltr\"\u003EDecoding the JWT:\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EIn your application, decode the JWT to extract user information and group memberships.\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Ccode\u003Eimport jwt\n\ndef decode_jwt(token):\n    try:\n        payload = jwt.decode(token, options={\"verify_signature\": False})\n        return payload\n    except jwt.ExpiredSignatureError:\n        return \"Token has expired\"\n    except jwt.InvalidTokenError:\n        return \"Invalid token\"\n\n# Example usage\ntoken = request.headers.get('Authorization').split(' ')\nuser_info = decode_jwt(token)\nprint(user_info)\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\n\u003Ch3 dir=\"ltr\"\u003EConclusion&nbsp;\u003C\u002Fh3\u003E\n\u003Cp dir=\"ltr\"\u003EImplementing OAuth2 authorization with Keycloak and Gatekeeper provides a robust and secure authentication mechanism for web applications. Here are some key consequences and considerations:\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EGatekeeper improves application security by centralizing authentication and session verification, eliminating the need for authentication logic within the application code and reducing the risk of vulnerabilities. Its scalability is ideal for Kubernetes deployments, and it supports various authentication methods like cookies and bearer tokens. Centralized management of authentication mechanisms simplifies updates and maintenance. Furthermore, using OIDC and OAuth2 with PKCE ensures adherence to security best practices and protects against common threats, making it a robust and compliant solution.\u003C\u002Fp\u003E\n\u003Cp dir=\"ltr\"\u003EIn summary, integrating Keycloak with Gatekeeper provides a comprehensive and secure solution for authentication and authorization, making it an ideal choice for protecting web applications in a Kubernetes environment.\u003C\u002Fp\u003E",slug:"implementing-oauth2-authorization-with-keycloak-gatekeeper",user_created:{id:b,first_name:c,last_name:d,email:e,password:f,location:a,title:g,description:a,tags:a,avatar:h,language:a,tfa_secret:a,status:i,role:j,token:a,last_access:k,last_page:l,provider:m,external_identifier:a,auth_data:a,email_notifications:n,appearance:a,theme_dark:a,theme_light:a,theme_light_overrides:a,theme_dark_overrides:a},user_updated:{id:b,first_name:c,last_name:d,email:e,password:f,location:a,title:g,description:a,tags:a,avatar:h,language:a,tfa_secret:a,status:i,role:j,token:a,last_access:k,last_page:l,provider:m,external_identifier:a,auth_data:a,email_notifications:n,appearance:a,theme_dark:a,theme_light:a,theme_light_overrides:a,theme_dark_overrides:a},image:{id:"c647d7c0-b72b-4ce0-85ad-5d9c9ec973d7",storage:q,filename_disk:"c647d7c0-b72b-4ce0-85ad-5d9c9ec973d7.png",filename_download:"Screenshot_from_2025-02-18_18-18-58-removebg-preview.png",title:"Screenshot From 2025 02 18 18 18 58 Removebg Preview",type:r,folder:s,uploaded_by:b,created_on:"2025-02-18T12:50:28.280Z",modified_by:a,modified_on:"2025-02-18T12:50:28.839Z",charset:a,filesize:"71299",width:658,height:318,duration:a,embed:a,description:a,location:a,tags:a,metadata:{},focal_point_x:a,focal_point_y:a,tus_id:a,tus_data:a,uploaded_on:"2025-02-18T12:50:28.836Z"},tags:[{id:45,blog_id:u,tags_id:18},{id:46,blog_id:u,tags_id:19},{id:47,blog_id:u,tags_id:20}]}],_img:{"/_ipx/f_png/https://data.improwised.com/assets/a4f063d8-c3a5-4625-8617-41c37c2092e4.png%3Fwidth=auto%26height=auto":"\u002F_nuxt\u002Fimage\u002F0dce84.png","/_ipx/_/img/logo.png":"\u002F_nuxt\u002Fimage\u002Fd4c006.png","/_ipx/_/img/fonts/menu.svg":"\u002F_nuxt\u002Fimage\u002Fb7846b.svg","/_ipx/h_400,f_webp/https://data.improwised.com/assets/848b119e-0969-4831-b652-2b90987580a6":"\u002F_nuxt\u002Fimage\u002Fb179ac.webp","/_ipx/_/img/fonts/google-blue.svg":"\u002F_nuxt\u002Fimage\u002F342f2b.svg","/_ipx/_/img/fonts/linkedin-blue.svg":"\u002F_nuxt\u002Fimage\u002F23608e.svg","/_ipx/_/img/fonts/twitter-blue.svg":"\u002F_nuxt\u002Fimage\u002F2c1470.svg","/_ipx/_/img/fonts/facebook-blue.svg":"\u002F_nuxt\u002Fimage\u002F36ebdc.svg","/_ipx/_/img/fonts/whatsapp-blue.svg":"\u002F_nuxt\u002Fimage\u002F90c703.svg","/_ipx/s_75x27/img/logo.png":"\u002F_nuxt\u002Fimage\u002F36e495.png","/_ipx/_/img/fonts/facebook.svg":"\u002F_nuxt\u002Fimage\u002F710b89.svg","/_ipx/_/img/fonts/twitter.svg":"\u002F_nuxt\u002Fimage\u002F45ad31.svg","/_ipx/_/img/fonts/linkedin.svg":"\u002F_nuxt\u002Fimage\u002F285706.svg","/_ipx/_/img/fonts/up-open-big.svg":"\u002F_nuxt\u002Fimage\u002F2b0c17.svg","/_ipx/f_webp,h_400/https://data.improwised.com/assets/848b119e-0969-4831-b652-2b90987580a6":"\u002F_nuxt\u002Fimage\u002Fc7d8fb.webp"}}],fetch:{},mutations:[]}}(null,"f6ae4b64-c3c4-4f35-8b41-9f48088de4b1","Angita","Shah","angita.shah@improwised.com","**********","SEO Specialist","20d037d1-41ee-4efd-b034-1350a3ce336d","active","5ef170ac-f2e9-4b93-a9ea-5c54fcf0fa40","2025-02-28T11:37:20.865Z","\u002Fcontent\u002Fblog\u002F31","default",true,21,"published","AMZ","image\u002Fpng","46478a01-ff9b-4189-ad30-24734d885007",29,28,"Simplifying Ingress Management for Kubernetes: Deploying a Traefik Cluster with Automatic TLS",2380,30,"Comparing Open Application Model (OAM) with Other Application Deployment Models",186,"The Evolution of Kubernetes: Why Itâ€™s the Foundation, Not the Destination",225,"Implementing OAuth2 Authorization with Keycloak and Gatekeeper")));